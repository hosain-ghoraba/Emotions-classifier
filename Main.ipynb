{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TODO\n",
        "\n",
        "dimensions of the layers  \n",
        "<br>\n",
        "layers in/out data\n",
        "<br>\n",
        "\n",
        "Present the selected classes with some samples of the inputs and the obtained results in the same file\n",
        "<br>\n",
        "\n",
        "modify dataset perc to use\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Milestone 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Packages installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kagglehub\n",
        "!pip install imagehash\n",
        "!pip install tensorflow\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install tqdm\n",
        "print(\"done installing packages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import kagglehub\n",
        "import random\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.decomposition import PCA\n",
        "from time import time\n",
        "\n",
        "print(\"done importing packages\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Data preparaion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    dataset_folder = kagglehub.dataset_download('hussainghoraba/emotions-dataset')\n",
        "    DATASET_PATH = os.path.join(dataset_folder, 'Dataset')\n",
        "elif 'KAGGLE_URL_BASE' in os.environ:\n",
        "    DATASET_PATH = '/kaggle/input/emotions-dataset/Dataset'\n",
        "elif 'VSCODE_PID' in os.environ:\n",
        "    DATASET_PATH = './Dataset'\n",
        "else:\n",
        "    raise Exception('Unknown environment')\n",
        "\n",
        "print(\"done setting up dataset path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set random seed & some global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "TAREGT_SIZE_TUPLE = (512, 512)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
        "print(\"done setting up random seed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time calculation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_and_print_time(start_time):\n",
        "    end_time = time()\n",
        "    time_taken = end_time - start_time\n",
        "    hours = int(time_taken // 3600)\n",
        "    minutes = int((time_taken % 3600) // 60)\n",
        "    seconds = int((time_taken % 3600) % 60)\n",
        "    print(f'\\n Done in : {hours} h, {minutes} m, {seconds} s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load dataset into memory without dups, and with correct size, and equalize the number of images in each class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_start_time = time()\n",
        "total_images_count = sum(len(files) for _, _, files in os.walk(DATASET_PATH))\n",
        "print(f\"Total images in dataset: {total_images_count}\")\n",
        "data = []\n",
        "dups_pairs = set()\n",
        "\n",
        "# load only a small percentage of the dataset, for faster testing while developing\n",
        "DATASET_PERC_TO_USE = 1\n",
        "\n",
        "num_images_in_smallest_category = min(len(os.listdir(os.path.join(DATASET_PATH, folder))) for folder in os.listdir(DATASET_PATH))\n",
        "num_of_images_to_use_in_each_category = int(num_images_in_smallest_category * DATASET_PERC_TO_USE)\n",
        "num_of_categories = len(os.listdir(DATASET_PATH))\n",
        "total_images_to_load = int(num_images_in_smallest_category * num_of_categories * DATASET_PERC_TO_USE)\n",
        "\n",
        "with tqdm(total=total_images_to_load, desc=\"Loading images into memory...\") as pbar:\n",
        "    for subfolder in os.listdir(DATASET_PATH):\n",
        "        subfolder_path = os.path.join(DATASET_PATH, subfolder)\n",
        "        subfolder_hashes = {}\n",
        "\n",
        "        all_category_images = os.listdir(subfolder_path)\n",
        "        # we must use the same number of images from each category to avoid bias\n",
        "        images_to_load = random.sample(all_category_images, num_of_images_to_use_in_each_category)\n",
        "        \n",
        "        for img_file in images_to_load:\n",
        "            img_path = os.path.join(subfolder_path, img_file)\n",
        "            with Image.open(img_path) as img:\n",
        "                img = img.convert(\"RGB\").resize(TAREGT_SIZE_TUPLE)\n",
        "                img_arr = np.array(img)\n",
        "                img_hash = imagehash.phash(img)\n",
        "            if img_hash not in subfolder_hashes.keys():\n",
        "                data.append({\"img_path\": img_path, \"label\": subfolder, \"img_arr\": img_arr})\n",
        "                # key : hash, value : img_path\n",
        "                subfolder_hashes[img_hash] = img_path\n",
        "            else:\n",
        "                existing_duplicate = subfolder_hashes[img_hash]\n",
        "                dups_pairs.add((img_path, existing_duplicate))\n",
        "            pbar.update(1)\n",
        "        \n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# display dups\n",
        "for dup_pair in dups_pairs:\n",
        "    print(f\"Duplicate images found: {dup_pair[0]} and {dup_pair[1]}\")\n",
        "    img1 = Image.open(dup_pair[0])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img1)\n",
        "    plt.title(os.path.basename(dup_pair[0]))\n",
        "    plt.axis('off')\n",
        "    img2 = Image.open(dup_pair[1])\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img2)\n",
        "    plt.title(os.path.basename(dup_pair[1]))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "calculate_and_print_time(global_start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train/Test/Val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C_b_7bkU03Y",
        "outputId": "7f2ab7fd-d76a-42c0-ac0d-fee917e716d9"
      },
      "outputs": [],
      "source": [
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=(1 - train_ratio), stratify=df['label'], random_state=RANDOM_SEED)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=(test_ratio / (test_ratio + val_ratio)), stratify=temp_df['label'], random_state=RANDOM_SEED)\n",
        "\n",
        "# Print the sizes of each split\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n",
        "\n",
        "print(\"\\ntraining set:\")\n",
        "print(train_df['label'].value_counts())\n",
        "\n",
        "print(\"\\nvalidation set:\")\n",
        "print(val_df['label'].value_counts())\n",
        "\n",
        "print(\"\\ntest set:\")\n",
        "print(test_df['label'].value_counts())\n",
        "\n",
        "\n",
        "print(\"done splitting dataset into train, val, test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgDAdbjXbtMy"
      },
      "source": [
        "## **Model 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classes & Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def extend_depth(filters, depth):\n",
        "    return np.stack([filters] * depth, axis=-1)\n",
        "\n",
        "# form the image windows to be multiplied with the filters, then flatten them for fast matrix multiplication\n",
        "def get_image_flattened_windows(input_data, filter_size):\n",
        "    input_h, input_w, input_c = input_data.shape\n",
        "    output_h = input_h - filter_size + 1\n",
        "    output_w = input_w - filter_size + 1\n",
        "\n",
        "    col = np.zeros((output_h * output_w, filter_size * filter_size * input_c))\n",
        "    i = 0\n",
        "    for h in range(output_h):\n",
        "        for w in range(output_w):\n",
        "            cube = input_data[h:h+filter_size, w:w+filter_size, :]\n",
        "            col[i, :] = cube.flatten()\n",
        "            i += 1\n",
        "    return col\n",
        "\n",
        "class ConvLayer:\n",
        "    def __init__(self, filter_size=3, num_filters=5, filter_weights=None, input_shape=None):\n",
        "        self.filter_size = filter_size\n",
        "        self.num_filters = num_filters\n",
        "        if filter_weights is None:\n",
        "            filter_weights = np.random.normal(size=(num_filters, filter_size, filter_size)) * 0.1\n",
        "        self.filter_weights = filter_weights\n",
        "\n",
        "        input_h, input_w, input_c = input_shape\n",
        "\n",
        "        # extend the filter weights depth so that filter depth = input depth (input channels)\n",
        "        deep_filters = extend_depth(filter_weights, input_c)\n",
        "\n",
        "        # flatten the filters for fast matrix multiplication in the \"forward\" fuction\n",
        "        self.deep_filters = deep_filters.reshape(num_filters, -1)\n",
        "\n",
        "        # define the output shape\n",
        "        output_h = input_h - filter_size + 1\n",
        "        output_w = input_w - filter_size + 1\n",
        "        self.output_shape = (output_h, output_w, num_filters)\n",
        "\n",
        "    def forward(self, input_image):\n",
        "        output_h, output_w = self.output_shape[0], self.output_shape[1]\n",
        "        input_col = get_image_flattened_windows(input_image, self.filter_size)\n",
        "        output_flat = self.deep_filters @ input_col.T\n",
        "        output = output_flat.T.reshape(output_h, output_w, self.num_filters)\n",
        "        return output\n",
        "    \n",
        "\n",
        "class PoolingLayer:\n",
        "    def __init__(self, pool_size=2, pool_type='MAX', input_shape=None):\n",
        "        if pool_type not in ['MAX', 'AVERAGE']:\n",
        "            raise ValueError(\"pool_type must be either 'MAX' or 'AVERAGE'\")\n",
        "        self.pool_size = pool_size\n",
        "        self.pool_type = pool_type\n",
        "\n",
        "        input_h, input_w, input_c = input_shape\n",
        "        output_h = input_h // self.pool_size\n",
        "        output_w = input_w // self.pool_size\n",
        "        self.output = np.zeros(output_h, output_w, input_c)\n",
        "\n",
        "    def forward(self, input_image):\n",
        "        for i in range(self.output.shape[0]):\n",
        "            for j in range(self.output.shape[1]):\n",
        "                h_start = i * self.pool_size\n",
        "                h_end = h_start + self.pool_size\n",
        "                w_start = j * self.pool_size\n",
        "                w_end = w_start + self.pool_size\n",
        "\n",
        "                pool_window = input_image[h_start:h_end, w_start:w_end, :]\n",
        "\n",
        "                if self.pool_type == 'MAX':\n",
        "                    self.output[i, j, :] = np.max(pool_window, axis=(0, 1))\n",
        "                elif self.pool_type == 'AVERAGE':\n",
        "                    self.output[i, j, :] = np.mean(pool_window, axis=(0, 1))\n",
        "\n",
        "        return self.output\n",
        "\n",
        "def extract_image_features(image, filter_weights):\n",
        "    conv1_outpup = ConvLayer(filter_size=3, num_filters=5, filter_weights=filter_weights).forward(image)\n",
        "    pool1_output = PoolingLayer(pool_size=2, pool_type='MAX').forward(conv1_outpup)\n",
        "    relu1_output = Relu(pool1_output)\n",
        "\n",
        "    conv2_outpup = ConvLayer(filter_size=3, num_filters=5, filter_weights=filter_weights).forward(relu1_output)\n",
        "    pool2_output = PoolingLayer(pool_size=2, pool_type='MAX').forward(conv2_outpup)\n",
        "    relu2_output = Relu(pool2_output)\n",
        "\n",
        "    conv3_outpup = ConvLayer(filter_size=3, num_filters=5, filter_weights=filter_weights).forward(relu2_output)\n",
        "    pool3_output = PoolingLayer(pool_size=2, pool_type='MAX').forward(conv3_outpup)\n",
        "    relu3_output = Relu(pool3_output)\n",
        "\n",
        "    flattened = relu3_output.flatten()\n",
        "    return flattened\n",
        "\n",
        "\n",
        "def custom_kmeans(data, k):\n",
        "    # data is a 2d array, each row is an array containing \n",
        "    # the extracted features of images passed to model 1\n",
        "\n",
        "    rows_count = data.shape[0]\n",
        "\n",
        "    # Initialize centroids randomly\n",
        "    centroids = data[np.random.choice(rows_count, k, replace=False)]\n",
        "\n",
        "    while True:\n",
        "        # assign each sample to the nearest centroid\n",
        "        distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2)\n",
        "        labels = np.argmin(distances, axis=1) \n",
        "\n",
        "        # update centroids \n",
        "        new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n",
        "\n",
        "        # breack if difference between new and old centroids is small\n",
        "        tolerance = 1e-4\n",
        "        if np.all(np.linalg.norm(new_centroids - centroids, axis=1) < tolerance):\n",
        "            break\n",
        "\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return centroids, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the model to extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "filter_weights = np.stack([\n",
        "    np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]),\n",
        "    np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]]),\n",
        "    np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
        "    np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n",
        "    np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "], axis=0)\n",
        "\n",
        "# extract features from a single image to know their number,\n",
        "# because it is needed to create the array that holds all features\n",
        "single_image = df.iloc[0]['img_arr']\n",
        "num_features = extract_image_features(single_image, filter_weights).shape[0]\n",
        "\n",
        "features_arrays = np.zeros((len(df), num_features))\n",
        "with tqdm(total=len(df), desc=\"Extracting features...\") as pbar:\n",
        "    for i in range(len(df)):\n",
        "        img_arr = df.iloc[i]['img_arr']\n",
        "        features_arrays[i, :] = extract_image_features(img_arr, filter_weights)\n",
        "        pbar.update(1)\n",
        "\n",
        "calculate_and_print_time(start_time)\n",
        "# downsample the features arrays to only 128 dimensions\n",
        "# use PCA only if we have more than 128 feature arrays ,\n",
        "# this is because in PCA, the number of components (which is 128 in our case) \n",
        "# must be less than the number of samples.\n",
        "# if we have less than 128 feature arrays, we will just select random 128 features\n",
        "start_time = time()\n",
        "if features_arrays.shape[0] >= 128:\n",
        "    print(f\"appling PCA...\")\n",
        "    features_arrays = PCA(n_components=128).fit_transform(features_arrays)\n",
        "else:\n",
        "    print(f\"selecting random 128 features from {features_arrays.shape[0]} features\")\n",
        "    selected_indices = np.random.choice(features_arrays.shape[1], 128, replace=False)\n",
        "    features_arrays = features_arrays[:, selected_indices]\n",
        "\n",
        "calculate_and_print_time(start_time)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clustering "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "num_classes = len(df['label'].unique())\n",
        "centroids, labels = custom_kmeans(features_arrays, k= num_classes)\n",
        "\n",
        "print(\"centroids shape:\", centroids.shape)\n",
        "print(\"labels shape:\", labels.shape)\n",
        "\n",
        "calculate_and_print_time(start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Function to load and preprocess an image\n",
        "# def load_image(url=None, path=None, target_size=(512, 512)):\n",
        "#     \"\"\"Load an image from URL or local path and preprocess it.\"\"\"\n",
        "#     if url:\n",
        "#         response = requests.get(url)\n",
        "#         img = Image.open(BytesIO(response.content))\n",
        "#     elif path:\n",
        "#         img = Image.open(path)\n",
        "#     else:\n",
        "#         # Create a sample image if no source is provided\n",
        "#         img = Image.new('RGB', target_size, color=(73, 109, 137))\n",
        "\n",
        "#     # Resize the image\n",
        "#     img = img.resize(target_size)\n",
        "\n",
        "#     # Convert to numpy array\n",
        "#     img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "#     return img_array\n",
        "\n",
        "# # Test with a sample image (you can replace this URL with your own image)\n",
        "# # Using a sample image URL - replace with your own image or add code to load a local file\n",
        "# sample_image_url = \"https://images.wallpapersden.com/image/download/cat-green-eyed-muzzle_aWhnZ5SZmpqtpaSklGpmZ61qZmc.jpg\"\n",
        "# try:\n",
        "#     img = load_image(url=sample_image_url)\n",
        "# except:\n",
        "#     # If the URL doesn't work, create a simple test image\n",
        "#     img = np.zeros((512, 512, 3))\n",
        "#     # Add some shapes for testing\n",
        "#     img[100:400, 100:400, 0] = 1.0  # Red square\n",
        "#     img[200:300, 200:300, 1] = 1.0  # Green square inside red\n",
        "\n",
        "# Initialize a ConvLayer with the predefined filters\n",
        "# conv_layer = ConvLayer(filter_size=3, num_filters=5, filter_weights=filters_3d)\n",
        "\n",
        "# # Apply convolution\n",
        "# feature_maps = conv_layer.forward(img)\n",
        "\n",
        "# # Visualize the original image and the feature maps\n",
        "# plt.figure(figsize=(15, 8))\n",
        "\n",
        "# # Original image\n",
        "# plt.subplot(2, 3, 1)\n",
        "# plt.imshow(img)\n",
        "# plt.title('Original Image')\n",
        "# plt.axis('off')\n",
        "\n",
        "# # Feature maps\n",
        "# filter_names = ['Box Filter (a)', 'Identity Filter (b)', 'Sobel X (c)', 'Sobel Y (d)', 'Sharpening (e)']\n",
        "\n",
        "# for i in range(5):\n",
        "#     plt.subplot(2, 3, i+2)\n",
        "#     # Normalize the feature map for better visualization\n",
        "#     feature_map = feature_maps[:, :, i]\n",
        "#     feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min() + 1e-8)\n",
        "#     plt.imshow(feature_map, cmap='viridis')\n",
        "#     plt.title(f'Filter {i+1}: {filter_names[i]}')\n",
        "#     plt.axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "# # Test individual filters\n",
        "# print(\"\\nTesting individual filters:\")\n",
        "# for i, (filter_name, filter_3d) in enumerate(zip(filter_names, [filter_a_3d, filter_b_3d, filter_c_3d, filter_d_3d, filter_e_3d])):\n",
        "#     # Create a ConvLayer with a single filter\n",
        "#     single_filter = np.expand_dims(filter_3d, axis=0)\n",
        "#     conv_layer_single = ConvLayer(filter_size=3, num_filters=1, filter_weights=single_filter)\n",
        "\n",
        "#     # Apply convolution\n",
        "#     feature_map = conv_layer_single.forward(img)\n",
        "\n",
        "#     print(f\"Filter {i+1} ({filter_name}) applied successfully.\")\n",
        "\n",
        "print(\"done model 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7VknR2cbydf"
      },
      "source": [
        "## **Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "xFDVzn_qb359",
        "outputId": "a0c234e1-4fc7-4dfb-f08e-32af3e76f40a"
      },
      "outputs": [],
      "source": [
        "# TA Dinah : \"You should have 5 convolution blocks each with 3 layers.\n",
        "#  3 convolution layers are simply 3 different filters on the same stage.\n",
        "#  A convolution block is some conv filters (layers) followed by an activation function and then a max pooling. \n",
        "# All convolution filters in the same block need to have the same size.\"\n",
        "\n",
        "def create_model2():\n",
        "    model = models.Sequential([\n",
        "    \n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='valid', input_shape=(TAREGT_SIZE_TUPLE[0], TAREGT_SIZE_TUPLE[1], 3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(32, (5, 5), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(32, (5, 5), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(32, (5, 5), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(16, (7, 7), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(16, (7, 7), activation='relu', padding='valid'),\n",
        "    layers.Conv2D(16, (7, 7), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    # 128 is OUR CHOICE for the number of neurons in the hidden layer (not specified in the project description)\n",
        "    layers.Dense(128, activation='sigmoid'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss='categorical_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model2 = create_model2()\n",
        "\n",
        "\n",
        "print(\"done building model 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early stopping to prevent overfitting (for the BONUS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
        "                                            patience=2,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr = 0.00001,\n",
        "                                            verbose = 1)\n",
        "\n",
        "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data augmentation (for the BONUS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# thiss will rotate the images by up to 20 degrees, also will increase the \n",
        "# dataset size on the fly while training \n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2 training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4GKqc0Yfl5e",
        "outputId": "7862dc2e-3b93-4508-d04a-01be54e7f565"
      },
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "batch_size = 16\n",
        "epochs = 10\n",
        "\n",
        "# print trining dataset size before and after augmentation\n",
        "print(f\"Training dataset size before augmentation: {len(train_df)}\")\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    target_size=TAREGT_SIZE_TUPLE,\n",
        "    x_col='img_path',  \n",
        "    y_col='label',    \n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical', \n",
        "    shuffle=True\n",
        ")\n",
        "print(f\"Training dataset size after augmentation: {train_gen.n}\")\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    target_size=TAREGT_SIZE_TUPLE,\n",
        "    x_col='img_path',\n",
        "    y_col='label',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "print(f\"images sizes passed to image data generator: {train_gen.image_shape}\")\n",
        "\n",
        "test_gen = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    target_size=TAREGT_SIZE_TUPLE,\n",
        "    x_col='img_path',\n",
        "    y_col='label',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "model2_history = model2.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=[early_stoping, learning_rate_reduction],\n",
        "    epochs=epochs,\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(test_gen)\n",
        "print(f\"Val accuracy: {model2_history.history['val_accuracy'][-1]:.2f}\")\n",
        "print(f\"Test accuracy: {test_acc:.2f}\")\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "JMOPXDv7hYqe",
        "outputId": "f4a6c5ed-9f4e-4057-9374-fa663d72add1"
      },
      "outputs": [],
      "source": [
        "# # Get class indices and reverse mapping\n",
        "# class_indices = test_gen.class_indices\n",
        "# class_labels = list(class_indices.keys())\n",
        "\n",
        "# # Get predictions for the test set\n",
        "# preds = model.predict(test_gen)\n",
        "# predicted_classes = np.argmax(preds, axis=1)\n",
        "# true_classes = test_gen.classes\n",
        "# filenames = test_gen.filenames\n",
        "\n",
        "# # Display 10 random images with predictions\n",
        "# num_images = 10\n",
        "# indices = np.random.choice(len(filenames), num_images, replace=False)\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "\n",
        "# for i, idx in enumerate(indices):\n",
        "#     img_path = os.path.join(test_dir, filenames[idx])\n",
        "#     img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
        "#     img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "\n",
        "#     plt.subplot(2, 5, i + 1)\n",
        "#     plt.imshow(img_array)\n",
        "#     plt.axis('off')\n",
        "#     true_label = class_labels[true_classes[idx]]\n",
        "#     predicted_label = class_labels[predicted_classes[idx]]\n",
        "#     title_color = \"green\" if true_label == predicted_label else \"red\"\n",
        "#     plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color=title_color)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"done displaying predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Milestone 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **model 1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy vs iterations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to be implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to be implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to be implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **model 2**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy vs iterations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(model2_history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(model2_history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = time()\n",
        "k = 4\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "fold_accuracies = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
        "    print(f\"\\nStarting fold {fold + 1}/{k}...\")\n",
        "    \n",
        "    train_data = df.iloc[train_idx]\n",
        "    val_data = df.iloc[val_idx]\n",
        "    \n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        x_col='img_path',\n",
        "        y_col='label',\n",
        "        target_size=TAREGT_SIZE_TUPLE,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "    \n",
        "    val_gen = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_data,\n",
        "        x_col='img_path',\n",
        "        y_col='label',\n",
        "        target_size=TAREGT_SIZE_TUPLE,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    model2 = create_model2()\n",
        "    \n",
        "    model2_history = model2.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[early_stoping, learning_rate_reduction],\n",
        "        epochs=epochs,\n",
        "    )\n",
        "    \n",
        "    val_accuracy = model2.evaluate(val_gen)[1]\n",
        "    print(f\"\\nFold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "\n",
        "average_accuracy = sum(fold_accuracies) / k\n",
        "print(f\"All folds validation accuracies: {fold_accuracies}\")\n",
        "print(f\"Average Accuracy: {average_accuracy:.2f}\")\n",
        "\n",
        "\n",
        "calculate_and_print_time(start_time)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_confusion_matrix(model, val_gen, plt_title):\n",
        "    y_true = val_gen.classes\n",
        "    print(f\"y_true : {y_true}\")\n",
        "    y_pred = model.predict(val_gen)\n",
        "    # print(f\"y_pred : {y_pred}\")\n",
        "    y_pred_classes = y_pred.argmax(axis=1)\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=val_gen.class_indices.keys())\n",
        "    disp.plot(cmap='viridis')\n",
        "    plt.title(plt_title)\n",
        "    plt.show()\n",
        "\n",
        "display_confusion_matrix(model2, val_gen, \"Confusion Matrix for model 2\")\n",
        "calculate_and_print_time(global_start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### notes : model2 problem is not in the model architecture (varified this by trying on bachelor model architecture, got similar results) so the problem is most likely in the data, or some where else in the code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
